{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Project Part 3","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-28T18:35:14.617999Z","iopub.execute_input":"2023-11-28T18:35:14.618391Z","iopub.status.idle":"2023-11-28T18:35:14.624137Z","shell.execute_reply.started":"2023-11-28T18:35:14.618362Z","shell.execute_reply":"2023-11-28T18:35:14.623229Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"input_data_path = 'https://raw.githubusercontent.com/Matthew-Bustamante/CS39AA-Project-Cyberbullying/main/CyberBullying_Comments_Dataset.csv'\ndf = pd.read_csv(input_data_path)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-28T18:35:16.478168Z","iopub.execute_input":"2023-11-28T18:35:16.478565Z","iopub.status.idle":"2023-11-28T18:35:16.988423Z","shell.execute_reply.started":"2023-11-28T18:35:16.478535Z","shell.execute_reply":"2023-11-28T18:35:16.987446Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                                Text  CB_Label\n0  damn there is someones nana up here at beach w...         0\n1  no kidding! dick clark was a corpse mechanical...         0\n2  i read an article on jobros and thought damn w...         0\n3  I got one fucking day of sprinkles and now it'...         0\n4  I was already listening to Elliott smith  and ...         0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>CB_Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>damn there is someones nana up here at beach w...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>no kidding! dick clark was a corpse mechanical...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>i read an article on jobros and thought damn w...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I got one fucking day of sprinkles and now it'...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I was already listening to Elliott smith  and ...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\nfrom datasets import Dataset, load_metric","metadata":{"execution":{"iopub.status.busy":"2023-11-28T18:35:22.555261Z","iopub.execute_input":"2023-11-28T18:35:22.556116Z","iopub.status.idle":"2023-11-28T18:35:22.560593Z","shell.execute_reply.started":"2023-11-28T18:35:22.556064Z","shell.execute_reply":"2023-11-28T18:35:22.559610Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"MODEL_NAME = \"bert-base-cased\"\nMAX_LENGTH=50 \n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\nmodel = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=3, max_length=MAX_LENGTH, output_attentions=False, output_hidden_states=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T18:35:24.509734Z","iopub.execute_input":"2023-11-28T18:35:24.510466Z","iopub.status.idle":"2023-11-28T18:35:25.745180Z","shell.execute_reply.started":"2023-11-28T18:35:24.510435Z","shell.execute_reply":"2023-11-28T18:35:25.744337Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Creating Vocabulary for y(dependent variable).  Note that 0 = non-cyberbullying and 1 = cyberbullying","metadata":{}},{"cell_type":"code","source":"classes = df.CB_Label.unique().tolist()\nclass_tok2idx = dict((v, k) for k, v in enumerate(classes))\nclass_idx2tok = dict((k, v) for k, v in enumerate(classes))\nprint(class_tok2idx)\nprint(class_idx2tok)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T18:36:11.379678Z","iopub.execute_input":"2023-11-28T18:36:11.380071Z","iopub.status.idle":"2023-11-28T18:36:11.389726Z","shell.execute_reply.started":"2023-11-28T18:36:11.380022Z","shell.execute_reply":"2023-11-28T18:36:11.388807Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"{0: 0, 1: 1}\n{0: 0, 1: 1}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Creating a new column with these labels which will be the y that is used","metadata":{}},{"cell_type":"code","source":"df['label'] = df['CB_Label'].apply(lambda x: class_tok2idx[x])\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-28T18:39:03.535930Z","iopub.execute_input":"2023-11-28T18:39:03.536365Z","iopub.status.idle":"2023-11-28T18:39:03.555679Z","shell.execute_reply.started":"2023-11-28T18:39:03.536332Z","shell.execute_reply":"2023-11-28T18:39:03.554658Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                                Text  CB_Label  label\n0  damn there is someones nana up here at beach w...         0      0\n1  no kidding! dick clark was a corpse mechanical...         0      0\n2  i read an article on jobros and thought damn w...         0      0\n3  I got one fucking day of sprinkles and now it'...         0      0\n4  I was already listening to Elliott smith  and ...         0      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>CB_Label</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>damn there is someones nana up here at beach w...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>no kidding! dick clark was a corpse mechanical...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>i read an article on jobros and thought damn w...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I got one fucking day of sprinkles and now it'...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I was already listening to Elliott smith  and ...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"'''\nsequence_0 = \"@united I will never fly with you again. Period.\"\nseq0_tokens = tokenizer(sequence_0, return_tensors=\"pt\")\nprint(f\"number of tokens in seq0 is {len(seq0_tokens['input_ids'].flatten())}\")\nprint(seq0_tokens)\nF.softmax(model(**seq0_tokens).logits, dim=1)\n'''","metadata":{"execution":{"iopub.status.busy":"2023-11-28T18:40:42.546327Z","iopub.execute_input":"2023-11-28T18:40:42.546972Z","iopub.status.idle":"2023-11-28T18:40:42.592179Z","shell.execute_reply.started":"2023-11-28T18:40:42.546939Z","shell.execute_reply":"2023-11-28T18:40:42.591092Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"number of tokens in seq0 is 14\n{'input_ids': tensor([[  101,   137, 10280,   146,  1209,  1309,  4689,  1114,  1128,  1254,\n           119, 16477,   119,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[14], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumber of tokens in seq0 is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(seq0_tokens[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mflatten())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(seq0_tokens)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mF\u001b[49m\u001b[38;5;241m.\u001b[39msoftmax(model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mseq0_tokens)\u001b[38;5;241m.\u001b[39mlogits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'F' is not defined"],"ename":"NameError","evalue":"name 'F' is not defined","output_type":"error"}]}]}